{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, target_size=(768, 768), ship_ratio=0.5):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Filter images without ships\n",
    "        images_with_ship = self.data[self.data['EncodedPixels'].notnull()]\n",
    "        num_images_with_ship = len(images_with_ship)\n",
    "\n",
    "        # Calculate the number of images without ships dynamically\n",
    "        num_images_without_ship = int(num_images_with_ship / ship_ratio) - num_images_with_ship\n",
    "\n",
    "        # Ensure at least one image without ships is included\n",
    "        num_images_without_ship = max(num_images_without_ship, 1)\n",
    "\n",
    "        # Sample images without ships without replacement\n",
    "        images_without_ship = self.data[self.data['EncodedPixels'].isnull()].sample(\n",
    "            n=num_images_without_ship, random_state=42, replace=False)\n",
    "\n",
    "        # Concatenate the two subsets\n",
    "        self.data = pd.concat([images_with_ship, images_without_ship], ignore_index=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, self.data.columns.get_loc('ImageId')])\n",
    "\n",
    "        try:\n",
    "            # Load the image using PIL\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "            # Resize the image to the target size\n",
    "            image = image.resize(self.target_size)\n",
    "\n",
    "            # Assuming you have a column 'EncodedPixels' for masks\n",
    "            mask_str = self.data.iloc[idx, self.data.columns.get_loc('EncodedPixels')]  \n",
    "\n",
    "            # Convert the mask string to a NumPy array\n",
    "            mask = rle_decode(mask_str, target_size=self.target_size)\n",
    "\n",
    "            # Convert the mask to a PIL image\n",
    "            mask = Image.fromarray(mask)\n",
    "\n",
    "            # Apply transformations to convert to tensors\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),])\n",
    "\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "\n",
    "            sample = {'image': image, 'mask': mask}\n",
    "\n",
    "            # print(\"Sample:\", sample)  \n",
    "\n",
    "            return sample\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)} Could not load image at {img_name}\")\n",
    "            return None  \n",
    "\n",
    "\n",
    "# Function to decode RLE-encoded masks to NumPy arrays\n",
    "def rle_decode(mask_rle, target_size=(768, 768)):\n",
    "    if pd.isna(mask_rle):  # Handle missing masks\n",
    "        return np.zeros(target_size, dtype=np.uint8)\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(np.prod(target_size), dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(target_size, order='F')\n",
    "\n",
    "csv_file = \"C:\\\\Users\\\\Микола\\\\Downloads\\\\airbus-ship-detection\\\\train_ship_segmentations_v2.csv\"\n",
    "root_dir = \"C:\\\\Users\\\\Микола\\\\Downloads\\\\airbus-ship-detection\\\\train_v2\"\n",
    "\n",
    "# Create an instance of the dataset\n",
    "custom_dataset = CustomDataset(csv_file=csv_file, root_dir=root_dir)\n",
    "\n",
    "# Calculate the index for splitting into train and validation sets\n",
    "split_index = int(0.8 * len(custom_dataset))\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(custom_dataset, [split_index, len(custom_dataset) - split_index])\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "batch_size = 16  \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Downsampling path\n",
    "        self.conv1 = self.conv_block(3, 8)\n",
    "        self.conv2 = self.conv_block(8, 16)\n",
    "        self.conv3 = self.conv_block(16, 32)\n",
    "        self.conv4 = self.conv_block(32, 64)\n",
    "\n",
    "        # Upsampling path\n",
    "        self.upconv4 = self.upconv_block(64, 32)\n",
    "        self.upconv3 = self.upconv_block(32, 16, skip_channels=32)\n",
    "        self.upconv2 = self.upconv_block(16, 8, skip_channels=16)\n",
    "        self.upconv1 = self.upconv_block(8, 8, skip_channels=8)\n",
    "\n",
    "        # Final convolutional layer\n",
    "        self.final_conv = nn.Conv2d(8, 1, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels, skip_channels=0):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels + skip_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Downsampling\n",
    "        x1 = self.conv1(x)\n",
    "        # print(\"Shape after conv1:\", x1.shape)\n",
    "        x2 = self.conv2(x1)\n",
    "        # print(\"Shape after conv2:\", x2.shape)\n",
    "        x3 = self.conv3(x2)\n",
    "        # print(\"Shape after conv3:\", x3.shape)\n",
    "        x4 = self.conv4(x3)\n",
    "        # print(\"Shape after conv4:\", x4.shape)\n",
    "\n",
    "        # Upsampling with skip connections\n",
    "        x = self.upconv4(x4)\n",
    "        # print(\"Shape after upconv4:\", x.shape)\n",
    "        x = self.upconv3(torch.cat([x, x3], dim=1)) \n",
    "        # print(\"Shape after upconv3:\", x.shape)\n",
    "        x = self.upconv2(torch.cat([x, x2], dim=1))  \n",
    "        # print(\"Shape after upconv2:\", x.shape)\n",
    "        x = self.upconv1(torch.cat([x, x1], dim=1))  \n",
    "        # print(\"Shape after upconv1:\", x.shape)\n",
    "\n",
    "        # Final convolutional layer\n",
    "        x = self.final_conv(x)\n",
    "        # print(\"Shape after final_conv:\", x.shape)\n",
    "        return x\n",
    "\n",
    "model = UNet()\n",
    "# print(model)\n",
    "\n",
    "# Sample input\n",
    "batch_size = 8\n",
    "input_channels = 3\n",
    "input_height = 768\n",
    "input_width = 768\n",
    "sample_input = torch.randn((batch_size, input_channels, input_height, input_width))\n",
    "\n",
    "# Forward pass\n",
    "output_conv = model(sample_input)\n",
    "\n",
    "# # Final convolution\n",
    "# output_final = model.final_conv(output_upconv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Dice Score function\n",
    "def dice_score(pred, target, smooth=1.0):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "# Move the model to GPU if available;\n",
    "device = torch.device(\"cuda:0\")\n",
    "assert torch.cuda.is_available(), \"CUDA is not available on this machine.\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  ####################### change? \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        images = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "\n",
    "        # Explicitly send the input tensor to the GPU\n",
    "        images = images.to(device)\n",
    "\n",
    "        # # Print information about the images\n",
    "        # print(\"Batch Shape:\", images.shape)\n",
    "        # print(\"Min Pixel Value:\", images.min())\n",
    "        # print(\"Max Pixel Value:\", images.max())\n",
    "        # print(\"Unique Pixel Values:\", torch.unique(images))\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate Dice Score (assuming binary segmentation)\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        dice = dice_score(predictions > 0.5, masks)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    average_dice = total_dice / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}, Average Dice Score: {average_dice:.4f}\")\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "total_dice_val = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_val in tqdm(val_loader, desc=\"Validation\"):\n",
    "        images_val = batch_val['image'].to(device)\n",
    "        masks_val = batch_val['mask'].to(device)\n",
    "\n",
    "        # Explicitly send the input tensor to the GPU\n",
    "        images_val = images_val.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_val = model(images_val)\n",
    "\n",
    "        # Calculate Dice Score (assuming binary segmentation)\n",
    "        predictions_val = torch.sigmoid(outputs_val)\n",
    "        dice_val = dice_score(predictions_val > 0.5, masks_val)\n",
    "\n",
    "        total_dice_val += dice_val\n",
    "\n",
    "average_dice_val = total_dice_val / len(val_loader)\n",
    "print(f\"Average Dice Score on Validation Set: {average_dice_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
